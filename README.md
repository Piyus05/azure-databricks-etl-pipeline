# Azure Databricks ETL Pipeline (Simulated)

This repository demonstrates a **realistic end-to-end ETL pipeline** using Apache Spark and Azure Databricks concepts.  
It simulates modern data engineering practices â€” from raw ingestion to transformed outputs ready for analytics.

---

## ğŸ” Project Overview

This project simulates a data pipeline that:

1. Loads raw data (CSV file)  
2. Cleans and deduplicates it  
3. Performs transformation and aggregations  
4. Outputs a curated dataset ready for analytics

Although running locally, this structure mirrors how **Azure Databricks + Delta Lake + Azure Data Factory** pipelines work in enterprise deployments.

---

## ğŸ§  Tech Stack

| Technology | Purpose |
|------------|---------|
| Python PySpark | Data processing |
| Apache Spark | Distributed ETL engine |
| Delta Lake concepts | Reliable table storage |
| SQL | Data validation |
| GitHub | Portfolio & version control |

---

## ğŸ“ Repository Structure

